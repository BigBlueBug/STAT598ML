{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code we use to simulate our Vokta Loterra and Lorenz systems. This is also the place where we play with 'torchdiffeq'. As mentioned in \n",
    "the project report, we use the author's implementation directly for our application as it simplifies a lot of the process, and since our code is inefficient to \n",
    "simulate slightly more complicated dynamical systems. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code here is taken from the blog of Dr.Kevin Hannay. Here is the link for the same: \n",
    "https://khannay.github.io/paramfittorchdemo/training.html#examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint as odeint ##This is the author's created module that we said we will use. \n",
    "import pylab as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Callable, List, Tuple, Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')  ##Testing this on Gilbreth will have Cuda but my local machine only has a cpu\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lets make a new class of objects called Lotkavolterra, using Pytorch's nn.Module framework\n",
    "\n",
    "class LotkaVolterra(nn.Module):\n",
    "    ####\n",
    "    #### We've already discussed that LT equations are a pair of first order non-linear eqs\n",
    "    ####\n",
    "    def __init__(self,\n",
    "                 alpha: float = 1.5, #alpha in the eqs\n",
    "                 beta: float = 1.0, #beta in the eqs\n",
    "                 delta: float = 3.0, #delta in the eqs\n",
    "                 gamma: float = 1.0 #gamma in the eqs\n",
    "                 ) -> None:\n",
    "        super().__init__() #same super type structure that is there in the author's code\n",
    "        self.model_params = torch.nn.Parameter(torch.tensor([alpha, beta, delta, gamma]))\n",
    "        \n",
    "        \n",
    "    def forward(self, t, state): #forward dir\n",
    "        x = state[...,0]      #variables are part of vector array u \n",
    "        y = state[...,1]\n",
    "        sol = torch.zeros_like(state)\n",
    "        \n",
    "        #coefficients are part of tensor model_params\n",
    "        alpha, beta, delta, gamma = self.model_params    \n",
    "        sol[...,0] = alpha*x - beta*x*y\n",
    "        sol[...,1] = -delta*y + gamma*x*y\n",
    "        return sol\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\" alpha: {self.model_params[0].item()}, \\\n",
    "            beta: {self.model_params[1].item()}, \\\n",
    "                delta: {self.model_params[2].item()}, \\\n",
    "                    gamma: {self.model_params[3].item()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##making the LV model for reference w.r.t our simulations.\n",
    "lv_model = LotkaVolterra() #using default parameters\n",
    "ts = torch.linspace(0,30.0,1000) \n",
    "batch_size = 30\n",
    "# Creating a batch of initial conditions (batch_dim, state_dim) as small perturbations around one value\n",
    "initial_conditions = torch.tensor([[3,3]]) + 0.50*torch.randn((batch_size,2))\n",
    "sol = odeint(lv_model, initial_conditions, ts, method='dopri5').detach().numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now get to data generation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimODEData(Dataset):\n",
    "    #dataset class\n",
    "    def __init__(self,\n",
    "                 ts: List[torch.Tensor], # List of time points as tensors\n",
    "                 values: List[torch.Tensor], # List of dynamical state values (tensor) at each time point \n",
    "                 true_model: Union[torch.nn.Module,None] = None,\n",
    "                 ) -> None:\n",
    "        self.ts = ts \n",
    "        self.values = values \n",
    "        self.true_model = true_model\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ts)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.ts[index], self.values[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sim_dataset(model: nn.Module, # model to simulate from\n",
    "                       ts: torch.Tensor, # Time points to simulate for\n",
    "                       num_samples: int = 10, # Number of samples to generate\n",
    "                       sigma_noise: float = 0.1, # Noise level to add to the data\n",
    "                       initial_conditions_default: torch.Tensor = torch.tensor([0.0, 0.0]), # Default initial conditions\n",
    "                       sigma_initial_conditions: float = 0.1, # Noise level to add to the initial conditions\n",
    "                       ) -> SimODEData:\n",
    "    ts_list = [] \n",
    "    states_list = [] \n",
    "    dim = initial_conditions_default.shape[0]\n",
    "    for i in range(num_samples):\n",
    "        x0 = sigma_initial_conditions * torch.randn((1,dim)).detach() + initial_conditions_default\n",
    "        ys = odeint(model, x0, ts).squeeze(1).detach() \n",
    "        ys += sigma_noise*torch.randn_like(ys)\n",
    "        ys[0,:] = x0 # Set the first value to the initial condition\n",
    "        ts_list.append(ts)\n",
    "        states_list.append(ys)\n",
    "    return SimODEData(ts_list, states_list, true_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plotting in time space now. \n",
    "def plot_time_series(true_model: torch.nn.Module, # true underlying model for the simulated data\n",
    "                     fit_model: torch.nn.Module, # model fit to the data\n",
    "                     data: SimODEData, # data set to plot (scatter)\n",
    "                     time_range: tuple = (0.0, 30.0), # range of times to simulate the models for\n",
    "                     ax: plt.Axes = None, \n",
    "                     dyn_var_idx: int = 0,\n",
    "                     title: str = \"Model fits\",\n",
    "                     *args,\n",
    "                     **kwargs) -> Tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Plot the true model and fit model on the same axes.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "        \n",
    "    vdp_model = VDP(mu = 0.10) \n",
    "    ts = torch.linspace(time_range[0], time_range[1], 1000)\n",
    "    ts_data, y_data = data\n",
    "\n",
    "    initial_conditions = y_data[0, :].unsqueeze(0)\n",
    "    sol_pred = odeint(fit_model, initial_conditions, ts, method='dopri5').detach().numpy()\n",
    "    sol_true = odeint(true_model, initial_conditions, ts, method='dopri5').detach().numpy()\n",
    "        \n",
    "    ax.plot(ts, sol_pred[:,:,dyn_var_idx], color='red', lw=2.0, label='Predicted', **kwargs);\n",
    "    ax.scatter(ts_data.detach(), y_data[:,dyn_var_idx].detach(), color='black', s=10, label='Data',  **kwargs);\n",
    "    ax.plot(ts, sol_true[:,:,dyn_var_idx], color='blue', ls='--', lw=1.5, label='True model', **kwargs);\n",
    "    ax.set_title(title);\n",
    "    ax.set_xlabel(\"t\");\n",
    "    ax.set_ylabel(\"y\");\n",
    "    plt.legend();\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting in phase space\n",
    "def plot_phase_plane(true_model: torch.nn.Module, # true underlying model for the simulated data\n",
    "                     fit_model: torch.nn.Module, # model fit to the data\n",
    "                     data: SimODEData, # data set to plot (scatter)\n",
    "                     time_range: tuple = (0.0, 30.0), # range of times to simulate the models for\n",
    "                     ax: plt.Axes = None, \n",
    "                     dyn_var_idx: tuple = (0,1),\n",
    "                     title: str = \"Model fits\",\n",
    "                     *args,\n",
    "                     **kwargs) -> Tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Plot the true model and fit model on the same axes.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "        \n",
    "    ts = torch.linspace(time_range[0], time_range[1], 1000)\n",
    "    ts_data, y_data = data\n",
    "    \n",
    "    initial_conditions = y_data[0, :].unsqueeze(0)\n",
    "    sol_pred = odeint(fit_model, initial_conditions, ts, method='dopri5').detach().numpy()\n",
    "    sol_true = odeint(true_model, initial_conditions, ts, method='dopri5').detach().numpy()\n",
    "    \n",
    "    idx1, idx2 = dyn_var_idx\n",
    "    \n",
    "    ax.plot(sol_pred[:,:,idx1], sol_pred[:,:,idx2], color='red', lw=2.0, label='Fitted');\n",
    "    ax.scatter(y_data[:,idx1], y_data[:,idx2].detach(), color='black', s=10, label='Noisy data');\n",
    "    ax.plot(sol_true[:,:,idx1], sol_true[:,:,idx2], color='blue', ls='--', lw=1.0, label='Real model');\n",
    "    ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(r'$y$')\n",
    "    ax.set_title(title)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining our training function:\n",
    "def train(model: torch.nn.Module, # Model to train\n",
    "          data: SimODEData, # Data to train on\n",
    "          lr: float = 1e-2, # learning rate for the Adam optimizer\n",
    "          epochs: int = 10, # Number of epochs to train for\n",
    "          batch_size: int = 5, # Batch size for training\n",
    "          method = 'rk4', # ODE solver to use\n",
    "          step_size: float = 0.10, # for fixed diffeq solver set the step size\n",
    "          show_every: int = 10, # How often to print the loss function message\n",
    "          save_plots_every: Union[int,None] = None, # save a plot of the fit, to disable make this None\n",
    "          model_name: str = \"\", #string for the model, used to reference the saved plots \n",
    "          *args: tuple, \n",
    "          **kwargs: dict\n",
    "          ):\n",
    "    \n",
    "    # Create a data loader to iterate over the data. This takes in our dataset and returns batches of data\n",
    "    trainloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    # Choose an optimizer. Adam is a good default choice as a fancy gradient descent\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # Create a loss function this computes the error between the predicted and true values\n",
    "    criterion = torch.nn.MSELoss() \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0 \n",
    "        for batchdata in trainloader:\n",
    "            optimizer.zero_grad() # reset gradients, famous gotcha in a pytorch training loop\n",
    "            ts, states = batchdata # unpack the data \n",
    "            initial_state = states[:,0,:] # grab the initial state\n",
    "            # Make the prediction and then flip the dimensions to be (batch, state_dim, time)\n",
    "            # Pytorch expects the batch dimension to be first\n",
    "            pred = odeint(model, initial_state, ts[0], method=method, options={'step_size': step_size}).transpose(0,1) \n",
    "            # Compute the loss\n",
    "            loss = criterion(pred, states)\n",
    "            # compute gradients\n",
    "            loss.backward() \n",
    "            # update parameters\n",
    "            optimizer.step() \n",
    "            running_loss += loss.item() # record loss\n",
    "        if epoch % show_every == 0:\n",
    "            print(f\"Loss at {epoch}: {running_loss}\")\n",
    "        # Use this to save plots of the fit every save_plots_every epochs\n",
    "        if save_plots_every is not None and epoch % save_plots_every == 0:\n",
    "            with torch.no_grad():\n",
    "                fig, ax = plot_time_series(data.true_model, model, data[0])\n",
    "                ax.set_title(f\"Epoch: {epoch}\")\n",
    "                fig.savefig(f\"./tmp_plots/{epoch}_{model_name}_fit_plot\")\n",
    "                plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LV model fitting now\n",
    "model_sim_lv = LotkaVolterra(1.5,1.0,3.0,1.0)\n",
    "ts_data = torch.arange(0.0, 10.0, 0.1)\n",
    "data_lv = create_sim_dataset(model_sim_lv, \n",
    "                              ts = ts_data, \n",
    "                              num_samples=10, \n",
    "                              sigma_noise=0.1,\n",
    "                              initial_conditions_default=torch.tensor([2.5, 2.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lv = LotkaVolterra(alpha=1.6, beta=1.1,delta=2.7, gamma=1.2) \n",
    "\n",
    "plot_time_series(model_sim_lv, model_lv, data = data_lv[0], title = \"Lotka Volterra: Before Fitting\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##training the model to fit it now: \n",
    "train(model_lv, data_lv, epochs=60, lr=1e-2, model_name=\"lotkavolterra\")\n",
    "print(f\"Fitted model: {model_lv}\")\n",
    "print(f\"True model: {model_sim_lv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(model_sim_lv, model_lv, data = data_lv[0], title = \"Lotka Volterra: After Fitting\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorenz system now: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lorenz(nn.Module):\n",
    "    \"\"\" \n",
    "    Define the Lorenz system as a PyTorch module.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 sigma: float =7.0, # The sigma parameter of the Lorenz system\n",
    "                 rho: float=10.0, # The rho parameter of the Lorenz system\n",
    "                beta: float=7.0/3, # The beta parameter of the Lorenz system\n",
    "                ):\n",
    "        super().__init__() \n",
    "        self.model_params = torch.nn.Parameter(torch.tensor([sigma, rho, beta]))\n",
    "        \n",
    "        \n",
    "    def forward(self, t, state):\n",
    "        x = state[...,0]      #variables are part of vector array u \n",
    "        y = state[...,1]\n",
    "        z = state[...,2]\n",
    "        sol = torch.zeros_like(state)\n",
    "        \n",
    "        sigma, rho, beta = self.model_params    #coefficients are part of vector array p\n",
    "        sol[...,0] = sigma*(y-x)\n",
    "        sol[...,1] = x*(rho-z) - y\n",
    "        sol[...,2] = x*y - beta*z\n",
    "        return sol\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\" sigma: {self.model_params[0].item()}, \\\n",
    "            rho: {self.model_params[1].item()}, \\\n",
    "                beta: {self.model_params[2].item()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_model = Lorenz()\n",
    "ts = torch.linspace(0,50.0,3000)\n",
    "batch_size = 30\n",
    "# Create a batch of initial conditions (batch_dim, state_dim) as small perturbations around one value\n",
    "initial_conditions = torch.tensor([[1.0,0.0,0.0]]) + 0.10*torch.randn((batch_size,3))\n",
    "sol = odeint(lorenz_model, initial_conditions, ts, method='dopri5').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sim_lorenz = Lorenz(sigma=10.0, rho=28.0, beta=8.0/3.0)\n",
    "ts_data = torch.arange(0, 10.0, 0.05)\n",
    "data_lorenz = create_sim_dataset(model_sim_lorenz, \n",
    "                              ts = ts_data, \n",
    "                              num_samples=30, \n",
    "                              initial_conditions_default=torch.tensor([1.0, 0.0, 0.0]),\n",
    "                              sigma_noise=0.01, \n",
    "                              sigma_initial_conditions=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_model = Lorenz(sigma=3.2, rho=18.2, beta=7.0/3) \n",
    "fig, ax = plot_time_series(model_sim_lorenz, lorenz_model, data_lorenz[0], title=\"Lorenz system before fitting from suggestion\");\n",
    "\n",
    "ax.set_xlim((2,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lorenz_model, \n",
    "      data_lorenz, \n",
    "      epochs=300, \n",
    "      batch_size=5,\n",
    "      method = 'rk4',\n",
    "      step_size=0.05,\n",
    "      show_every=50,\n",
    "      lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_time_series(model_sim_lorenz, lorenz_model, data_lorenz[0], title = \"Lorenz Model fit using advice\"); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
